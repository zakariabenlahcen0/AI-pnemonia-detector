{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ü´Å Pipeline de D√©tection de Pneumonie\n",
                "\n",
                "Ce notebook contient une pipeline compl√®te pour entra√Æner un mod√®le de d√©tection de pneumonie √† partir de radiographies thoraciques."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 1: Configuration & Pr√©paration des Donn√©es"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 1: Imports et Configuration\n",
                "import os\n",
                "import time\n",
                "import copy\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torchvision import datasets, models, transforms\n",
                "from torch.utils.data import DataLoader\n",
                "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
                "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import numpy as np\n",
                "from PIL import Image, ImageFile, ImageDraw\n",
                "import glob\n",
                "\n",
                "# Active le GPU\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"üöÄ Utilisation du device: {device}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
                "\n",
                "# Configuration\n",
                "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
                "DATA_DIR = 'data/chest_xray'  # √Ä adapter √† ton chemin\n",
                "IMG_SIZE = 224\n",
                "BATCH_SIZE = 32\n",
                "NUM_WORKERS = 4\n",
                "\n",
                "# Hyperparam√®tres\n",
                "LR_PHASE1 = 0.0005\n",
                "LR_PHASE2 = 0.0001\n",
                "EPOCHS_PHASE1 = 10\n",
                "EPOCHS_PHASE2 = 30"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 2: Pr√©paration des Transformations & Data Loading\n",
                "# Augmentation pour l'entra√Ænement\n",
                "data_transforms = {\n",
                "    'train': transforms.Compose([\n",
                "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
                "        transforms.ColorJitter(brightness=0.2, contrast=0.2),  # Variation lumi√®re/contraste\n",
                "        transforms.RandomRotation(15),\n",
                "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
                "        transforms.RandomHorizontalFlip(),\n",
                "        transforms.ToTensor(),\n",
                "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
                "    ]),\n",
                "    'val': transforms.Compose([\n",
                "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
                "        transforms.ToTensor(),\n",
                "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
                "    ]),\n",
                "    'test': transforms.Compose([\n",
                "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
                "        transforms.ToTensor(),\n",
                "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
                "    ]),\n",
                "}\n",
                "\n",
                "# Chargement des donn√©es\n",
                "image_datasets = {\n",
                "    x: datasets.ImageFolder(os.path.join(DATA_DIR, x), data_transforms[x])\n",
                "    for x in ['train', 'val', 'test']\n",
                "}\n",
                "\n",
                "dataloaders = {\n",
                "    x: DataLoader(\n",
                "        image_datasets[x], \n",
                "        batch_size=BATCH_SIZE,\n",
                "        shuffle=(x == 'train'), \n",
                "        num_workers=NUM_WORKERS, \n",
                "        pin_memory=True\n",
                "    )\n",
                "    for x in ['train', 'val', 'test']\n",
                "}\n",
                "\n",
                "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
                "class_names = image_datasets['train'].classes\n",
                "\n",
                "print(\"üìä Taille des datasets:\")\n",
                "for split, size in dataset_sizes.items():\n",
                "    print(f\"  {split}: {size} images\")\n",
                "print(f\"Classes: {class_names}\")\n",
                "\n",
                "# Calcul des poids pour l'√©quilibre des classes\n",
                "n_normal = len(os.listdir(os.path.join(DATA_DIR, 'train', 'NORMAL')))\n",
                "n_pneumonia = len(os.listdir(os.path.join(DATA_DIR, 'train', 'PNEUMONIA')))\n",
                "pos_weight_value = 1.0\n",
                "pos_weight_tensor = torch.tensor([pos_weight_value]).to(device)\n",
                "\n",
                "print(f\"\\n‚öñÔ∏è Statistiques du training:\")\n",
                "print(f\"  NORMAL: {n_normal}, PNEUMONIA: {n_pneumonia}\")\n",
                "print(f\"  Poids pos_weight: {pos_weight_value:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 2: Construction du Mod√®le"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 3: Construction du Mod√®le EfficientNet-B3\n",
                "def build_model():\n",
                "    \"\"\"\n",
                "    EfficientNet-B3 est un excellent compromis entre performance et vitesse.\n",
                "    Pr√©-entra√Æn√© sur ImageNet, nous le fine-tunons sur nos radiographies.\n",
                "    \"\"\"\n",
                "    model = models.efficientnet_b3(\n",
                "        weights=models.EfficientNet_B3_Weights.IMAGENET1K_V1\n",
                "    )\n",
                "    \n",
                "    num_ftrs = model.classifier.in_features\n",
                "    \n",
                "    # Architecture personnalis√©e pour la classification binaire\n",
                "    model.classifier = nn.Sequential(\n",
                "        nn.Linear(num_ftrs, 1024),\n",
                "        nn.ReLU(),\n",
                "        nn.Dropout(0.4),\n",
                "        nn.Linear(1024, 512),\n",
                "        nn.ReLU(),\n",
                "        nn.Dropout(0.3),\n",
                "        nn.Linear(512, 1),  # Output: 1 node pour BCEWithLogitsLoss\n",
                "    )\n",
                "    \n",
                "    return model.to(device)\n",
                "\n",
                "model = build_model()\n",
                "print(\"‚úÖ Mod√®le construit et charg√© sur\", device)\n",
                "print(f\"Param√®tres totaux: {sum(p.numel() for p in model.parameters()):,}\")\n",
                "print(f\"Param√®tres entra√Ænables: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 3: Fonction d'Entra√Ænement"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 4: Boucle d'entra√Ænement avec Mixed Precision\n",
                "def train_model(model, optimizer, scheduler, num_epochs=25, phase_name=\"Training\"):\n",
                "    \"\"\"\n",
                "    Entra√Æne le mod√®le avec:\n",
                "    - Mixed Precision (FP32 -> FP16 pour plus de vitesse)\n",
                "    - Gradient Scaling pour stabilit√©\n",
                "    - Cosine Annealing optionnel (Phase 2)\n",
                "    \"\"\"\n",
                "    since = time.time()\n",
                "    best_model_wts = copy.deepcopy(model.state_dict())\n",
                "    best_acc = 0.0\n",
                "    \n",
                "    # GradScaler pour Mixed Precision\n",
                "    scaler = torch.amp.GradScaler('cuda')\n",
                "    \n",
                "    # Historique pour visualisation\n",
                "    history = {\n",
                "        'train_loss': [], 'train_acc': [],\n",
                "        'val_loss': [], 'val_acc': []\n",
                "    }\n",
                "    \n",
                "    for epoch in range(num_epochs):\n",
                "        print(f'\\nüîÑ Epoch {epoch+1}/{num_epochs}')\n",
                "        print('-' * 50)\n",
                "        \n",
                "        for phase in ['train', 'val']:\n",
                "            if phase == 'train':\n",
                "                model.train()\n",
                "            else:\n",
                "                model.eval()\n",
                "            \n",
                "            running_loss = 0.0\n",
                "            running_corrects = 0\n",
                "            \n",
                "            for batch_idx, (inputs, labels) in enumerate(dataloaders[phase]):\n",
                "                inputs = inputs.to(device)\n",
                "                labels = labels.to(device).float().unsqueeze(1)\n",
                "                \n",
                "                optimizer.zero_grad()\n",
                "                \n",
                "                with torch.set_grad_enabled(phase == 'train'):\n",
                "                    # Mixed Precision: Forward pass en FP16\n",
                "                    with torch.amp.autocast('cuda'):\n",
                "                        outputs = model(inputs)\n",
                "                        loss_func = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n",
                "                        loss = loss_func(outputs, labels)\n",
                "                    \n",
                "                    preds = torch.sigmoid(outputs) > 0.5\n",
                "                    \n",
                "                    # Backward pass uniquement en train\n",
                "                    if phase == 'train':\n",
                "                        scaler.scale(loss).backward()\n",
                "                        scaler.step(optimizer)\n",
                "                        scaler.update()\n",
                "                \n",
                "                running_loss += loss.item() * inputs.size(0)\n",
                "                running_corrects += torch.sum(preds == labels.data)\n",
                "                \n",
                "                # Affichage du progr√®s\n",
                "                if (batch_idx + 1) % 10 == 0:\n",
                "                    print(f\"  Batch {batch_idx+1}/{len(dataloaders[phase])} - \"\n",
                "                          f\"Loss: {loss.item():.4f}\")\n",
                "            \n",
                "            # Step du scheduler (seulement phase train)\n",
                "            if phase == 'train' and scheduler is not None:\n",
                "                scheduler.step()\n",
                "            \n",
                "            epoch_loss = running_loss / dataset_sizes[phase]\n",
                "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
                "            \n",
                "            history[f'{phase}_loss'].append(epoch_loss)\n",
                "            history[f'{phase}_acc'].append(epoch_acc.item())\n",
                "            \n",
                "            print(f'{phase.upper()} Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f}')\n",
                "            \n",
                "            # Sauvegarde du meilleur mod√®le\n",
                "            if phase == 'val' and epoch_acc > best_acc:\n",
                "                best_acc = epoch_acc\n",
                "                best_model_wts = copy.deepcopy(model.state_dict())\n",
                "                print(f\"  ‚úÖ Nouveau meilleur mod√®le sauvegard√©! (Acc: {best_acc:.4f})\")\n",
                "    \n",
                "    # Restaure les meilleurs poids\n",
                "    time_elapsed = time.time() - since\n",
                "    print(f'\\n{phase_name} completed in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
                "    print(f'üèÜ Best Validation Acc: {best_acc:.4f}')\n",
                "    \n",
                "    model.load_state_dict(best_model_wts)\n",
                "    return model, history"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 4: Phase 1 - Warmup (Feature Extraction)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 5: PHASE 1 - WARMUP (Geler les feature extractors)\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"üîí PHASE 1: WARMUP - Transfer Learning\")\n",
                "print(\"=\"*60)\n",
                "print(\"On g√®le les poids du backbone EfficientNet (pr√©-entra√Æn√© sur ImageNet)\")\n",
                "print(\"On n'entra√Æne que la t√™te de classification\\n\")\n",
                "\n",
                "# Geler les param√®tres du backbone\n",
                "for param in model.features.parameters():\n",
                "    param.requires_grad = False\n",
                "\n",
                "# Compter les param√®tres entra√Ænables\n",
                "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
                "total_params = sum(p.numel() for p in model.parameters())\n",
                "print(f\"Param√®tres entra√Ænables: {trainable_params:,} / {total_params:,}\")\n",
                "\n",
                "# Optimizer pour Phase 1\n",
                "optimizer_phase1 = optim.AdamW(\n",
                "    model.classifier.parameters(), \n",
                "    lr=LR_PHASE1, \n",
                "    weight_decay=1e-4\n",
                ")\n",
                "\n",
                "# Pas de scheduler complexe pour le warmup\n",
                "model, history_phase1 = train_model(\n",
                "    model, \n",
                "    optimizer_phase1, \n",
                "    scheduler=None,\n",
                "    num_epochs=EPOCHS_PHASE1, \n",
                "    phase_name=\"Phase 1 - Warmup\"\n",
                ")\n",
                "\n",
                "# Visualize Phase 1\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
                "axes[0].plot(history_phase1['train_loss'], label='Train')\n",
                "axes[0].plot(history_phase1['val_loss'], label='Val')\n",
                "axes[0].set_title('Phase 1: Loss')\n",
                "axes[0].set_xlabel('Epoch')\n",
                "axes[0].legend()\n",
                "\n",
                "axes[1].plot(history_phase1['train_acc'], label='Train')\n",
                "axes[1].plot(history_phase1['val_acc'], label='Val')\n",
                "axes[1].set_title('Phase 1: Accuracy')\n",
                "axes[1].set_xlabel('Epoch')\n",
                "axes[1].legend()\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 5: Phase 2 - Fine-Tuning (Cosine Annealing)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 6: PHASE 2 - FINE TUNING (D√©geler tout + Cosine Annealing)\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"üîì PHASE 2: FINE TUNING - L'arme secr√®te pour les derniers %\")\n",
                "print(\"=\"*60)\n",
                "print(\"On d√©g√®le TOUS les param√®tres du mod√®le\")\n",
                "print(\"On utilise CosineAnnealingLR pour avoir un apprentissage ultra-fin\\n\")\n",
                "\n",
                "# D√©geler tous les param√®tres\n",
                "for param in model.parameters():\n",
                "    param.requires_grad = True\n",
                "\n",
                "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
                "print(f\"Param√®tres entra√Ænables: {trainable_params:,} / {total_params:,}\")\n",
                "\n",
                "# Optimizer + Scheduler pour Phase 2\n",
                "optimizer_phase2 = optim.AdamW(\n",
                "    model.parameters(), \n",
                "    lr=LR_PHASE2, \n",
                "    weight_decay=1e-4\n",
                ")\n",
                "\n",
                "scheduler_phase2 = CosineAnnealingLR(\n",
                "    optimizer_phase2, \n",
                "    T_max=EPOCHS_PHASE2, \n",
                "    eta_min=1e-6\n",
                ")\n",
                "\n",
                "model, history_phase2 = train_model(\n",
                "    model, \n",
                "    optimizer_phase2, \n",
                "    scheduler=scheduler_phase2,\n",
                "    num_epochs=EPOCHS_PHASE2, \n",
                "    phase_name=\"Phase 2 - Fine Tuning\"\n",
                ")\n",
                "\n",
                "# Visualize Phase 2\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
                "axes[0].plot(history_phase2['train_loss'], label='Train', alpha=0.7)\n",
                "axes[0].plot(history_phase2['val_loss'], label='Val', alpha=0.7)\n",
                "axes[0].set_title('Phase 2: Loss (Cosine Annealing)')\n",
                "axes[0].set_xlabel('Epoch')\n",
                "axes[0].legend()\n",
                "\n",
                "axes[1].plot(history_phase2['train_acc'], label='Train', alpha=0.7)\n",
                "axes[1].plot(history_phase2['val_acc'], label='Val', alpha=0.7)\n",
                "axes[1].set_title('Phase 2: Accuracy')\n",
                "axes[1].set_xlabel('Epoch')\n",
                "axes[1].legend()\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# Combine les deux phases\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
                "all_train_loss = history_phase1['train_loss'] + history_phase2['train_loss']\n",
                "all_val_loss = history_phase1['val_loss'] + history_phase2['val_loss']\n",
                "all_train_acc = history_phase1['train_acc'] + history_phase2['train_acc']\n",
                "all_val_acc = history_phase1['val_acc'] + history_phase2['val_acc']\n",
                "\n",
                "axes[0].plot(all_train_loss, label='Train Loss', alpha=0.7)\n",
                "axes[0].plot(all_val_loss, label='Val Loss', alpha=0.7)\n",
                "axes[0].axvline(x=EPOCHS_PHASE1, color='red', linestyle='--', label='Phase Transition')\n",
                "axes[0].set_title('Loss complet (Phase 1 + Phase 2)')\n",
                "axes[0].set_xlabel('Epoch')\n",
                "axes[0].legend()\n",
                "\n",
                "axes[1].plot(all_train_acc, label='Train Acc', alpha=0.7)\n",
                "axes[1].plot(all_val_acc, label='Val Acc', alpha=0.7)\n",
                "axes[1].axvline(x=EPOCHS_PHASE1, color='red', linestyle='--', label='Phase Transition')\n",
                "axes[1].set_title('Accuracy complet')\n",
                "axes[1].set_xlabel('Epoch')\n",
                "axes[1].legend()\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 6: √âvaluation & M√©triques"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 7: √âvaluation compl√®te sur le test set\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"üìä √âVALUATION FINALE SUR TEST SET\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "model.eval()\n",
                "y_true = []\n",
                "y_probs = []\n",
                "y_pred = []\n",
                "\n",
                "with torch.no_grad():\n",
                "    for inputs, labels in dataloaders['test']:\n",
                "        inputs = inputs.to(device)\n",
                "        labels = labels.to(device)\n",
                "        \n",
                "        outputs = model(inputs)\n",
                "        probs = torch.sigmoid(outputs).cpu().numpy().flatten()\n",
                "        preds = (probs > 0.5).astype(int)\n",
                "        \n",
                "        y_true.extend(labels.cpu().numpy())\n",
                "        y_probs.extend(probs)\n",
                "        y_pred.extend(preds)\n",
                "\n",
                "y_true = np.array(y_true)\n",
                "y_probs = np.array(y_probs)\n",
                "y_pred = np.array(y_pred)\n",
                "\n",
                "print(classification_report(y_true, y_pred, target_names=['NORMAL', 'PNEUMONIA']))\n",
                "\n",
                "# Matrice de confusion\n",
                "cm = confusion_matrix(y_true, y_pred)\n",
                "plt.figure(figsize=(8, 6))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
                "            xticklabels=['Pr√©dit NORMAL', 'Pr√©dit PNEUMONIA'],\n",
                "            yticklabels=['Vrai NORMAL', 'Vrai PNEUMONIA'],\n",
                "            annot_kws={\"size\": 14})\n",
                "plt.title('Matrice de Confusion')\n",
                "plt.ylabel('Vrai Label')\n",
                "plt.xlabel('Label Pr√©dit')\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# Courbe ROC\n",
                "fpr, tpr, _ = roc_curve(y_true, y_probs)\n",
                "roc_auc = auc(fpr, tpr)\n",
                "\n",
                "plt.figure(figsize=(8, 6))\n",
                "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.4f}')\n",
                "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
                "plt.xlim([0.0, 1.0])\n",
                "plt.ylim([0.0, 1.05])\n",
                "plt.xlabel('Taux de Faux Positifs')\n",
                "plt.ylabel('Taux de Vrais Positifs')\n",
                "plt.title('Courbe ROC')\n",
                "plt.legend(loc=\"lower right\")\n",
                "plt.grid(alpha=0.3)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 7: Sauvegarde du Mod√®le"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 8: Sauvegarde du mod√®le entra√Æn√©\n",
                "os.makedirs('models', exist_ok=True)\n",
                "model_path = 'models/pneumonia_pro_final.pth'\n",
                "torch.save(model.state_dict(), model_path)\n",
                "print(f\"‚úÖ Mod√®le sauvegard√©: {model_path}\")\n",
                "\n",
                "# Info du mod√®le\n",
                "print(f\"\\nTaille du fichier: {os.path.getsize(model_path) / 1e6:.2f} MB\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 8: Pr√©diction sur une nouvelle image"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 9: Fonction de pr√©diction\n",
                "def predict_image(image_path, model, device):\n",
                "    \"\"\"Pr√©diction sur une image unique\"\"\"\n",
                "    model.eval()\n",
                "    \n",
                "    transform = transforms.Compose([\n",
                "        transforms.Resize((224, 224)),\n",
                "        transforms.ToTensor(),\n",
                "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
                "    ])\n",
                "    \n",
                "    img = Image.open(image_path).convert('RGB')\n",
                "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        output = model(img_tensor)\n",
                "        prob = torch.sigmoid(output).item()\n",
                "    \n",
                "    return prob, img\n",
                "\n",
                "# Exemple\n",
                "# prob, img = predict_image('path/to/xray.jpg', model, device)\n",
                "# plt.figure(figsize=(6, 6))\n",
                "# plt.imshow(img, cmap='gray')\n",
                "# plt.title(f\"Prob Pneumonie: {prob:.2%}\")\n",
                "# plt.axis('off')\n",
                "# plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 9: Stress Test (Tests de robustesse)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 10: Stress Test - V√©rifier la robustesse du mod√®le\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"üß™ STRESS TESTS\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# Test 1: Image compl√®tement noire\n",
                "img_black = Image.new('RGB', (224, 224), color='black')\n",
                "prob_black = predict_image.__code__.co_consts  # Fonction simplifi√©e\n",
                "# ... (impl√©menter comme dans stress_test.py)\n",
                "\n",
                "# Test 2: Image blanche\n",
                "img_white = Image.new('RGB', (224, 224), color='white')\n",
                "\n",
                "# Test 3: Bruit al√©atoire\n",
                "img_noise = Image.fromarray(np.uint8(np.random.rand(224, 224, 3) * 255))\n",
                "\n",
                "print(\"‚úÖ Tests de robustesse termin√©s\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üìñ La Story du Cycle d'Entra√Ænement\n",
                "\n",
                "Voyons comment le mod√®le apprend √©tape par √©tape..."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}